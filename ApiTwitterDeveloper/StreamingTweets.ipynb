{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis Exploratorio de Tweets\n",
    "Para obtener los datos de Twitter debemos usar la [API ingresa](https://developer.twitter.com/en/docs/twitter-api) a (Twitter Developers) y luego necesitas generar tus credenciales. Para ello crea un nuevo proyecto, deberás ponerle un nombre, descripción y propósito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraccion de Tweets\n",
    "Codigo Python para obtener todos los tweets por Cuenta (@) especifica de Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "api_key = \"contraseña_apikey\"\n",
    "api_key_secret = \"contraseña_api_key_secret\"\n",
    "access_token = \"-contraseña_access_token\"\n",
    "access_token_secret = \"contraseña_access_token_secret\"\n",
    "\n",
    "auth = tweepy.OAuth1UserHandler(\n",
    "   api_key, api_key_secret, access_token, access_token_secret\n",
    ")\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "# Iniciamos un array que va a contener los datos\n",
    "simple_list = []\n",
    "# Iniciamos el for con Cursor\n",
    "# Usamos algunos parámetros extra para excluir respuestas, retweets y traer el texto completo de cada tweet\n",
    "for status in tweepy.Cursor(api.user_timeline,\n",
    "                            screen_name = 'yourUser@', \n",
    "                            exclude_replies = True, \n",
    "                            include_rts = False,\n",
    "                            tweet_mode='extended').items(70):\n",
    " # Agregamos el texto, fecha, likes, retweets y hashtags al array\n",
    "    simple_list.append([status.full_text, status.created_at, status.favorite_count, status.retweet_count, [h['text'] for h in status.entities['hashtags']]])\n",
    "# Convertimos el array en un DataFrame y nombramos las columnas\n",
    "simple_list = pd.DataFrame(simple_list, columns=['Text', 'Created_at', 'Likes', 'Retweets', 'Hashtags'])\n",
    "# Guardamos en el directorio en que estamos trabajando\n",
    "simple_list\n",
    "simple_list.to_csv(\"testTweets.csv\", sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conexion a Base de Datos Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "conn_dwh = 'postgresql://postgres:Paswword@localhost/postgres'\n",
    "db = create_engine(conn_dwh)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraccion de Tweets por Palabras Claves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas insertadas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "\n",
    "api_key = \"contraseña_apikey\"\n",
    "api_key_secret = \"contraseña_api_key_secret\"\n",
    "access_token = \"-contraseña_access_token\"\n",
    "access_token_secret = \"contraseña_access_token_secret\"\n",
    "\n",
    "auth = tweepy.OAuth1UserHandler(api_key, api_key_secret, access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "search_list = []\n",
    "KEYWORDS = \"Olimpia\"\n",
    "\n",
    "# Basic keyword search with full text\n",
    "#tweets = api.search_tweets(KEYWORDS, tweet_mode=\"extended\")\n",
    "\n",
    "#Parámetros de la función search\n",
    "for status in tweepy.Cursor(api.search_tweets, KEYWORDS, result_type=\"recent\", tweet_mode=\"extended\").items(5):\n",
    "    search_list.append([status.full_text, status.created_at, status.favorite_count, status.retweet_count, status.lang, status.author.screen_name, status.id])\n",
    "\n",
    "search_list = pd.DataFrame(search_list, columns=['tweettext', 'created_at', 'likes', 'retweets', 'idioma', 'autor', 'idtw'])\n",
    "# Insert into table\n",
    "print('Filas insertadas')\n",
    "search_list.to_sql('Olimpiatext', con=conn_dwh, index=False, if_exists='replace',chunksize = 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consulta en la Base de Datos para comprobar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweettext</th>\n",
       "      <th>created_at</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>idioma</th>\n",
       "      <th>autor</th>\n",
       "      <th>idtw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @OlimpiaMedia: ❝Estábamos diez puntos abajo...</td>\n",
       "      <td>2022-11-09 17:31:41+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>es</td>\n",
       "      <td>lukitasj_</td>\n",
       "      <td>1590396724786651136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @sentiazulgrana: Nuestra esperanza es tener...</td>\n",
       "      <td>2022-11-09 17:31:27+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>es</td>\n",
       "      <td>dure_fa</td>\n",
       "      <td>1590396664866832384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stasera Bulegna merda due volte\\nC’è anche l’O...</td>\n",
       "      <td>2022-11-09 17:31:14+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>it</td>\n",
       "      <td>marcoluo</td>\n",
       "      <td>1590396607844925440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[TEMPORADA RÉCORD] \\nUn dato de color que deja...</td>\n",
       "      <td>2022-11-09 17:30:53+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>es</td>\n",
       "      <td>ivan_alexis__</td>\n",
       "      <td>1590396521371283457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Estigarribiapy_: \"La diferencia que tiene ...</td>\n",
       "      <td>2022-11-09 17:30:37+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>es</td>\n",
       "      <td>OlimpiaTweets</td>\n",
       "      <td>1590396452509192192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweettext  \\\n",
       "0  RT @OlimpiaMedia: ❝Estábamos diez puntos abajo...   \n",
       "1  RT @sentiazulgrana: Nuestra esperanza es tener...   \n",
       "2  Stasera Bulegna merda due volte\\nC’è anche l’O...   \n",
       "3  [TEMPORADA RÉCORD] \\nUn dato de color que deja...   \n",
       "4  RT @Estigarribiapy_: \"La diferencia que tiene ...   \n",
       "\n",
       "                 created_at  likes  retweets idioma          autor  \\\n",
       "0 2022-11-09 17:31:41+00:00      0        99     es      lukitasj_   \n",
       "1 2022-11-09 17:31:27+00:00      0        79     es        dure_fa   \n",
       "2 2022-11-09 17:31:14+00:00      0         0     it       marcoluo   \n",
       "3 2022-11-09 17:30:53+00:00      0         0     es  ivan_alexis__   \n",
       "4 2022-11-09 17:30:37+00:00      0        70     es  OlimpiaTweets   \n",
       "\n",
       "                  idtw  \n",
       "0  1590396724786651136  \n",
       "1  1590396664866832384  \n",
       "2  1590396607844925440  \n",
       "3  1590396521371283457  \n",
       "4  1590396452509192192  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Query1 = \"SELECT * FROM OlimpiaText\"\n",
    "dfTweetsOlimpia = pd.read_sql_query(Query1, conn_dwh)\n",
    "dfTweetsOlimpia"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b652e32c432ed5545f141cb780a5e94f3d33602200f84c18b384d39c5294c981"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
